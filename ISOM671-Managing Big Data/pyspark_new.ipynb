{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# LAST VERSION #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a716807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whole code\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.2.0')\n",
    "conf.set('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider')\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "df = spark.read.option(\"inferSchema\", \n",
    "\"true\").option(\"header\", \n",
    "\"true\").csv(\"s3://final-for-bigdata/Bigdata_project_final_data_final.csv\")\n",
    "\n",
    "#df.printSchema()\n",
    "\n",
    "#### data preparation for ML ##########\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['id','state','goal',\t'usd_pledged','backers_count','comments_count','updates_count','project_duration'\n",
    "                                               ,'country_AU','country_BE','country_CA','country_CH','country_DE','country_DK','country_ES','country_FR','country_GB','country_HK','country_IE','country_IT','country_JP','country_LU','country_MX','country_NL','country_NO','country_NZ','country_SE','country_SG','country_US'\n",
    "                                               ,'spotlight_True','staff_pick_True','disable_communication_True','profile_show_feature_image_True','profile_state_inactive'\n",
    "                                               ,'p_category_comics','p_category_crafts','p_category_dance','p_category_design','p_category_fashion','p_category_film & video','p_category_food','p_category_games','p_category_journalism','p_category_music','p_category_photography',\t'p_category_publishing','p_category_technology','p_category_theater']\n",
    "                                  , outputCol = 'features')\n",
    "v_df = vectorAssembler.transform(df)\n",
    "v_df = v_df.select(['features', 'state'])\n",
    "v_df.show(3)\n",
    "\n",
    "###### split data ################\n",
    "splits = v_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "#####build logistic ML model ############\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='state', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))\n",
    "training_sum = lr_model.summary\n",
    "training_sum.predictions.describe().show()\n",
    "\n",
    "#evaluate logistic regression model with AUC\n",
    "lr_prediction = lr_model.transform(test_df)\n",
    "lr_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='state')\n",
    "lr_auc = lr_eval.evaluate(lr_prediction)\n",
    "lr_auc\n",
    "\n",
    "#evaluate logistic regression model with accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "evaluatorMulti = MulticlassClassificationEvaluator(labelCol='state', predictionCol='prediction')\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='state', rawPredictionCol='prediction', metricName='areaUnderROC')\n",
    "\n",
    "l_prediction = lr_prediction.select('state', 'prediction')\n",
    "\n",
    "l_accuracy = evaluatorMulti.evaluate(l_prediction, {evaluatorMulti.metricName: 'accuracy'})\n",
    "l_accuracy\n",
    "\n",
    "########## random forest ################\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'state')\n",
    "rf_model = rf.fit(train_df)\n",
    "rf_prediction = rf_model.transform(test_df)\n",
    "\n",
    "#evaluate random forest model with AUC\n",
    "rf_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='state')\n",
    "rf_auc = rf_eval.evaluate(rf_prediction)\n",
    "rf_auc\n",
    "\n",
    "#evaluate random forest model with accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "evaluatorMulti = MulticlassClassificationEvaluator(labelCol='state', predictionCol='prediction')\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='state', rawPredictionCol='prediction', metricName='areaUnderROC')\n",
    "\n",
    "r_prediction = rf_prediction.select('state', 'prediction')\n",
    "\n",
    "r_accuracy = evaluatorMulti.evaluate(r_prediction, {evaluatorMulti.metricName: 'accuracy'})\n",
    "r_accuracy\n",
    "\n",
    "\n",
    "######\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'state')\n",
    "rf_model = rf.fit(train_df)\n",
    "rf_prediction = rf_model.transform(test_df)\n",
    "\n",
    "rf_eval = BinaryClassificationEvaluator(rawPredictionCol='features',labelCol='state')\n",
    "rf_auc = rf_eval.evaluate(rf_prediction)\n",
    "rf_auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99148a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## try\n",
    "predictionAndTarget =lr_prediction.select(\"state\", \"features\")\n",
    "\n",
    "acc = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "lr_prediction2 = lr_prediction.withColumn(\"state\",lr_prediction.state.cast('double'))\n",
    "lr_prediction2.head()\n",
    "#my_mc_lr = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='feature', metricName='f1')\n",
    "#my_mc_lr.evaluate(lr_prediction2)\n",
    "\n",
    "########## useless ##############\n",
    "trainingSummary = lr_model.summary\n",
    "\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
